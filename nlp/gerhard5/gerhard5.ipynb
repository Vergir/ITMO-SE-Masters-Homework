{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gerhard5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLmEWi7AKrEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "9ca3741b-c15d-4857-d171-ad98750c8601"
      },
      "source": [
        "import string\n",
        "import spacy\n",
        "import neuralcoref\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EghEwMKws_WH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENTITY = 0\n",
        "POS_TAG = 1\n",
        "\n",
        "PERSONAL_PRONOUN = 'PRP'\n",
        "\n",
        "def dumb_coref(ne_tree):\n",
        "  tokens = []\n",
        "  last_ne = None\n",
        "  \n",
        "  for node in ne_tree:\n",
        "    if type(node) is nltk.Tree:\n",
        "      tokens.append(' ')\n",
        "      last_ne = ' '.join([part[ENTITY] for part in node])\n",
        "      tokens.append(last_ne)\n",
        "    else:\n",
        "        \n",
        "      if node[POS_TAG] not in string.punctuation:\n",
        "        tokens.append(' ')\n",
        "\n",
        "      if node[POS_TAG] == PERSONAL_PRONOUN and last_ne:\n",
        "        tokens.append(last_ne)\n",
        "      else:\n",
        "        tokens.append(node[0])\n",
        "\n",
        "  res_text = ''.join(tokens).strip()\n",
        "  return res_text\n",
        "\n",
        "def dumb_coref_v2(ne_tree):\n",
        "  tokens = []\n",
        "  last_ne = None\n",
        "  \n",
        "  for i, node in enumerate(ne_tree):\n",
        "    if type(node) is nltk.Tree:\n",
        "      tokens.append(' ')\n",
        "      last_ne = ' '.join([part[ENTITY] for part in node])\n",
        "      tokens.append(last_ne)\n",
        "      if ne_tree[i-1][ENTITY] == 'and' and type(ne_tree[i-2]) is nltk.Tree:\n",
        "          last_ne = ' '.join([part[ENTITY] for part in ne_tree[i-2]]) + ' ' + ne_tree[i-1][ENTITY] + ' ' + last_ne\n",
        "    else:\n",
        "      if node[POS_TAG] not in string.punctuation:\n",
        "        tokens.append(' ')\n",
        "\n",
        "      if node[POS_TAG] == PERSONAL_PRONOUN and last_ne:\n",
        "        tokens.append(last_ne)\n",
        "      else:\n",
        "        tokens.append(node[0])\n",
        "\n",
        "  res_text = ''.join(tokens).strip()\n",
        "  return res_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fye6UAknudTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 1. Have some short input document (a couple of sentences, which contain Corefs.)\n",
        "\n",
        "INPUT_SENTENCES = [\n",
        "  'I had a friend Jim. Me and him had good times.',\n",
        "  'Monkey King is an important character of Eastern culture. Many people in Asia know stories about his adventures.',\n",
        "  'Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about his adventures.',\n",
        "  'Romeo and Juliet is one of the most famous love stories in the world. They won over many passionate readers across the whole globe.'\n",
        "]\n",
        "EXPECTED_RESULTS = [\n",
        "  'I had a friend Jim. Me and Jim had good times.',\n",
        "  'Monkey King is an important character of Eastern culture. Many people in Asia know stories about Monkey King adventures.',\n",
        "  'Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about Sun Wukong adventures.',\n",
        "  'Romeo and Juliet is one of the most famous love stories in the world. Romeo and Juliet won over many passionate readers across the whole globe.'\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di27oYn6TfW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 2. Apply POS-tagging to the document (with NLTK or spaCy)\n",
        "\n",
        "pos_tags = [None] * len(INPUT_SENTENCES)\n",
        "for i, sentence in enumerate(INPUT_SENTENCES):\n",
        "  pos_tags[i] = nltk.pos_tag(nltk.tokenize.word_tokenize(sentence))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqiQmqgDT4Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 3. Apply NE-Recognition to the document (with spaCy or NLTK)\n",
        "\n",
        "ne_trees = [None] * len(INPUT_SENTENCES)\n",
        "for i, sentence in enumerate(INPUT_SENTENCES):\n",
        "  ne_trees[i] = nltk.ne_chunk(pos_tags[i])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hra4YPZQUOKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "2f25cde5-7db9-4206-f49f-f2559d1f1326"
      },
      "source": [
        "#@markdown ###4. For any pronoun – replace it with previous Named Entity\n",
        "#@markdown ###5. Print to result text\n",
        "#@markdown ###6. Evaluate your system with a couple of input sentences – you are the domain expert!\n",
        "#@markdown ###7. Present results\n",
        "\n",
        "for i, sentence in enumerate(INPUT_SENTENCES):\n",
        "  dumb_coref_result = dumb_coref(ne_trees[i])\n",
        "  bleu_score = nltk.translate.bleu_score.sentence_bleu([EXPECTED_RESULT[i].split()], dumb_coref_result.split())\n",
        "  \n",
        "  print('INPUT')\n",
        "  print(sentence)\n",
        "  print('EXPECTED')\n",
        "  print(EXPECTED_RESULT[i])\n",
        "  print('DUMB COREF')\n",
        "  print(dumb_coref_result)\n",
        "  print(f'BLEU Score: {bleu_score}')\n",
        "  print()\n",
        "  "
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT\n",
            "I had a friend Jim. Me and him had good times.\n",
            "EXPECTED\n",
            "I had a friend Jim. Me and Jim had good times.\n",
            "DUMB COREF\n",
            "I had a friend Jim. Me and Jim had good times.\n",
            "BLEU Score: 1.0\n",
            "\n",
            "INPUT\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "EXPECTED\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about Monkey King adventures.\n",
            "DUMB COREF\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "BLEU Score: 0.8434168123760957\n",
            "\n",
            "INPUT\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "EXPECTED\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about Sun Wukong adventures.\n",
            "DUMB COREF\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "BLEU Score: 0.8434168123760957\n",
            "\n",
            "INPUT\n",
            "Romeo and Juliet is one of the most famous love stories in the world. They won over many passionate readers across the whole globe.\n",
            "EXPECTED\n",
            "Romeo and Juliet is one of the most famous love stories in the world. Romeo and Juliet won over many passionate readers across the whole globe.\n",
            "DUMB COREF\n",
            "Romeo and Juliet is one of the most famous love stories in the world. Juliet won over many passionate readers across the whole globe.\n",
            "BLEU Score: 0.8548651952212404\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QA5wBn5gQnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "c90aafa8-b3fd-465a-fef0-bdb14b9af75d"
      },
      "source": [
        "#@markdown ###8. Run spaCy coref on the same text\n",
        "#@markdown ###9. Compare evaluation results of spaCy and your system\n",
        "\n",
        "# you may need to downgrade spacy to 2.1.0\n",
        "# https://github.com/huggingface/neuralcoref/issues/158\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "for i, sentence in enumerate(INPUT_SENTENCES):\n",
        "  nlp_sentence = nlp(sentence)\n",
        "  spacy_coref_result = nlp_sentence._.coref_resolved\n",
        "  bleu_score = nltk.translate.bleu_score.sentence_bleu([EXPECTED_RESULT[i].split()], spacy_coref_result.split())\n",
        "  \n",
        "  print('INPUT')\n",
        "  print(sentence)\n",
        "  print('EXPECTED')\n",
        "  print(EXPECTED_RESULT[i])\n",
        "  print('SPACY COREF')\n",
        "  print(spacy_coref_result)\n",
        "  print(f'BLEU Score: {bleu_score}')\n",
        "  print()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT\n",
            "I had a friend Jim. Me and him had good times.\n",
            "EXPECTED\n",
            "I had a friend Jim. Me and Jim had good times.\n",
            "SPACY COREF\n",
            "I had a friend Jim. Me and a friend Jim had good times.\n",
            "BLEU Score: 0.6703420896351792\n",
            "\n",
            "INPUT\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "EXPECTED\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about Monkey King adventures.\n",
            "SPACY COREF\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about Monkey King adventures.\n",
            "BLEU Score: 1.0\n",
            "\n",
            "INPUT\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "EXPECTED\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about Sun Wukong adventures.\n",
            "SPACY COREF\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about Sun Wukong adventures.\n",
            "BLEU Score: 1.0\n",
            "\n",
            "INPUT\n",
            "Romeo and Juliet is one of the most famous love stories in the world. They won over many passionate readers across the whole globe.\n",
            "EXPECTED\n",
            "Romeo and Juliet is one of the most famous love stories in the world. Romeo and Juliet won over many passionate readers across the whole globe.\n",
            "SPACY COREF\n",
            "Romeo and Juliet is one of the most famous love stories in the world. Romeo and Juliet won over many passionate readers across the whole globe.\n",
            "BLEU Score: 1.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGI1wAKyLHi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "e2e3072f-37bf-4c3e-d888-5eba823a558d"
      },
      "source": [
        "#@title Bonus: Make your coref detection a bit more smart - if you want\n",
        "\n",
        "for i, sentence in enumerate(INPUT_SENTENCES):\n",
        "  dumb_coref_result = dumb_coref_v2(ne_trees[i])\n",
        "  bleu_score = nltk.translate.bleu_score.sentence_bleu([EXPECTED_RESULT[i].split()], dumb_coref_result.split())\n",
        "  \n",
        "  print('INPUT')\n",
        "  print(sentence)\n",
        "  print('EXPECTED')\n",
        "  print(EXPECTED_RESULT[i])\n",
        "  print('DUMB COREF')\n",
        "  print(dumb_coref_result)\n",
        "  print(f'BLEU Score: {bleu_score}')\n",
        "  print()"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT\n",
            "I had a friend Jim. Me and him had good times.\n",
            "EXPECTED\n",
            "I had a friend Jim. Me and Jim had good times.\n",
            "DUMB COREF\n",
            "I had a friend Jim. Me and Jim had good times.\n",
            "BLEU Score: 1.0\n",
            "\n",
            "INPUT\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "EXPECTED\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about Monkey King adventures.\n",
            "DUMB COREF\n",
            "Monkey King is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "BLEU Score: 0.8434168123760957\n",
            "\n",
            "INPUT\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "EXPECTED\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about Sun Wukong adventures.\n",
            "DUMB COREF\n",
            "Sun Wukong is an important character of Eastern culture. Many people in Asia know stories about his adventures.\n",
            "BLEU Score: 0.8434168123760957\n",
            "\n",
            "INPUT\n",
            "Romeo and Juliet is one of the most famous love stories in the world. They won over many passionate readers across the whole globe.\n",
            "EXPECTED\n",
            "Romeo and Juliet is one of the most famous love stories in the world. Romeo and Juliet won over many passionate readers across the whole globe.\n",
            "DUMB COREF\n",
            "Romeo and Juliet is one of the most famous love stories in the world. Romeo and Juliet won over many passionate readers across the whole globe.\n",
            "BLEU Score: 1.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}